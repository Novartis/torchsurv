{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca2213c2-6abc-4340-853a-7ab1e06e68d3",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "In this notebook, we use `TorchSurv` to train a model that predicts relative risk of breast cancer recurrence. We use a public data set, the [German Breast Cancer Study Group 2 (GBSG2)](https://paperswithcode.com/dataset/gbsg2). After training the model, we evaluate the predictive performance using evaluation metrics implemented in `TorchSurv`.\n",
    "\n",
    "\n",
    "We first load the dataset using the package [lifelines](https://lifelines.readthedocs.io/en/latest/). The GBSG2 dataset contains features and recurrence free survival time (in days) for 686 women undergoing hormonal treatment. \n",
    "\n",
    "### Dependencies\n",
    "\n",
    "To run this notebook, dependencies must be installed. the recommended method is to use our developpment conda environment (**preffered**). Instruction can be found [here](https://opensource.nibr.com/torchsurv/devnotes.html#set-up-a-development-environment-via-conda) to install all optional dependancies. The other method is to install only required packages using the command line below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "160c8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install only required packages (optional)\n",
    "# %pip install lifelines\n",
    "# %pip install matplotlib\n",
    "# %pip install sklearn\n",
    "# %pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "013dbcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2601dd00-7bd2-49d5-9bdf-a84205872890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lifelines\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Our package\n",
    "from torchsurv.loss.cox import neg_partial_log_likelihood\n",
    "from torchsurv.loss.weibull import neg_log_likelihood, log_hazard, survival_function\n",
    "from torchsurv.metrics.brier_score import BrierScore\n",
    "from torchsurv.metrics.cindex import ConcordanceIndex\n",
    "from torchsurv.metrics.auc import Auc\n",
    "from torchsurv.stats.kaplan_meier import KaplanMeierEstimator\n",
    "\n",
    "# PyTorch boilerplate - see https://github.com/Novartis/torchsurv/blob/main/docs/notebooks/helpers_introduction.py\n",
    "from helpers_introduction import Custom_dataset, plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7a98ea2-100f-43ef-8c45-c786ddcd313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA-enabled GPU/TPU is available.\n"
     ]
    }
   ],
   "source": [
    "# Constant parameters accross models\n",
    "# Detect available accelerator; Downgrade batch size if only CPU available\n",
    "if any([torch.cuda.is_available(), torch.backends.mps.is_available()]):\n",
    "    print(\"CUDA-enabled GPU/TPU is available.\")\n",
    "    BATCH_SIZE = 128  # batch size for training\n",
    "else:\n",
    "    print(\"No CUDA-enabled GPU found, using CPU.\")\n",
    "    BATCH_SIZE = 32  # batch size for training\n",
    "\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dd4c6e-2934-44f5-88fa-1d9d02032fc3",
   "metadata": {},
   "source": [
    "## Dataset overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1df49737-dc02-4d6b-acd7-d03b79f18a29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horTh</th>\n",
       "      <th>age</th>\n",
       "      <th>menostat</th>\n",
       "      <th>tsize</th>\n",
       "      <th>tgrade</th>\n",
       "      <th>pnodes</th>\n",
       "      <th>progrec</th>\n",
       "      <th>estrec</th>\n",
       "      <th>time</th>\n",
       "      <th>cens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>70</td>\n",
       "      <td>Post</td>\n",
       "      <td>21</td>\n",
       "      <td>II</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>66</td>\n",
       "      <td>1814</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>56</td>\n",
       "      <td>Post</td>\n",
       "      <td>12</td>\n",
       "      <td>II</td>\n",
       "      <td>7</td>\n",
       "      <td>61</td>\n",
       "      <td>77</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>58</td>\n",
       "      <td>Post</td>\n",
       "      <td>35</td>\n",
       "      <td>II</td>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "      <td>271</td>\n",
       "      <td>712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>59</td>\n",
       "      <td>Post</td>\n",
       "      <td>17</td>\n",
       "      <td>II</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>29</td>\n",
       "      <td>1807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>73</td>\n",
       "      <td>Post</td>\n",
       "      <td>35</td>\n",
       "      <td>II</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>65</td>\n",
       "      <td>772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  horTh  age menostat  tsize tgrade  pnodes  progrec  estrec  time  cens\n",
       "0    no   70     Post     21     II       3       48      66  1814     1\n",
       "1   yes   56     Post     12     II       7       61      77  2018     1\n",
       "2   yes   58     Post     35     II       9       52     271   712     1\n",
       "3   yes   59     Post     17     II       4       60      29  1807     1\n",
       "4    no   73     Post     35     II       1       26      65   772     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load GBSG2 dataset\n",
    "df = lifelines.datasets.load_gbsg2()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f23ce41-c0eb-4c30-83f3-2a2d45dcf097",
   "metadata": {},
   "source": [
    "The dataset contains the categorical features: \n",
    "\n",
    "- `horTh`: hormonal therapy, a factor at two levels (yes and no).\n",
    "- `age`:  age of the patients in years.\n",
    "- `menostat`: menopausal status, a factor at two levels pre (premenopausal) and post (postmenopausal).\n",
    "- `tsize`: tumor size (in mm).\n",
    "- `tgrade`: tumor grade, a ordered factor at levels I < II < III.\n",
    "- `pnodes`: number of positive nodes.\n",
    "- `progrec`: progesterone receptor (in fmol).\n",
    "- `estrec`: estrogen receptor (in fmol).\n",
    "\n",
    "Additionally, it contains our survival targets:\n",
    "\n",
    "- `time`: recurrence free survival time (in days).\n",
    "- `cens`: censoring indicator (0- censored, 1- event).\n",
    "\n",
    "One common approach is to use a [one hot encoder](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) to convert them into numerical features. We then seperate the dataframes into features `X` and labels `y`. The following code also partitions the labels and features into training and testing cohorts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34132fea-daa6-46a5-8429-16df73886a51",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a5fd9ef-2643-46b7-9c98-05ff919026ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>tsize</th>\n",
       "      <th>pnodes</th>\n",
       "      <th>progrec</th>\n",
       "      <th>estrec</th>\n",
       "      <th>time</th>\n",
       "      <th>cens</th>\n",
       "      <th>horTh_yes</th>\n",
       "      <th>menostat_Pre</th>\n",
       "      <th>tgrade_II</th>\n",
       "      <th>tgrade_III</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1814.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>712.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1807.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>772.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  tsize  pnodes  progrec  estrec    time  cens  horTh_yes  \\\n",
       "0  70.0   21.0     3.0     48.0    66.0  1814.0   1.0        0.0   \n",
       "1  56.0   12.0     7.0     61.0    77.0  2018.0   1.0        1.0   \n",
       "2  58.0   35.0     9.0     52.0   271.0   712.0   1.0        1.0   \n",
       "3  59.0   17.0     4.0     60.0    29.0  1807.0   1.0        1.0   \n",
       "4  73.0   35.0     1.0     26.0    65.0   772.0   1.0        0.0   \n",
       "\n",
       "   menostat_Pre  tgrade_II  tgrade_III  \n",
       "0           0.0        1.0         0.0  \n",
       "1           0.0        1.0         0.0  \n",
       "2           0.0        1.0         0.0  \n",
       "3           0.0        1.0         0.0  \n",
       "4           0.0        1.0         0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onehot = pd.get_dummies(df, columns=[\"horTh\", \"menostat\", \"tgrade\"]).astype(\"float\")\n",
    "df_onehot.drop(\n",
    "    [\"horTh_no\", \"menostat_Post\", \"tgrade_I\"],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")\n",
    "df_onehot.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f8b7f3b-fb2a-4d74-ac99-8f6390b2f5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Sample size) Training:336 | Validation:144 |Testing:206\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df_onehot, test_size=0.3)\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.3)\n",
    "print(\n",
    "    f\"(Sample size) Training:{len(df_train)} | Validation:{len(df_val)} |Testing:{len(df_test)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ad6603-0dff-4991-992a-081ba9a4fafa",
   "metadata": {},
   "source": [
    "Let us setup the dataloaders for training, validation and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "326c03fc-91f1-493b-a9ba-820de17fb2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "dataloader_train = DataLoader(\n",
    "    Custom_dataset(df_train), batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "dataloader_val = DataLoader(\n",
    "    Custom_dataset(df_val), batch_size=len(df_val), shuffle=False\n",
    ")\n",
    "dataloader_test = DataLoader(\n",
    "    Custom_dataset(df_test), batch_size=len(df_test), shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570386fb-f0ea-4061-bae2-11b274e7f851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "x, (event, time) = next(iter(dataloader_train))\n",
    "num_features = x.size(1)\n",
    "\n",
    "print(f\"x (shape)    = {x.shape}\")\n",
    "print(f\"num_features = {num_features}\")\n",
    "print(f\"event        = {event.shape}\")\n",
    "print(f\"time         = {time.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b53d40d-d2c4-4dd7-bb85-97d4e946c356",
   "metadata": {},
   "source": [
    "## Section 1: Cox proportional hazards model\n",
    "\n",
    "In this section, we use the [Cox proportional hazards model](../_autosummary/torchsurv.loss.cox.html). Given covariate $x_{i}$, the hazard of patient $i$ has the form\n",
    "$$\n",
    "\\lambda (t|x_{i}) =\\lambda_{0}(t)\\theta(x_{i})\n",
    "$$\n",
    "The baseline hazard $\\lambda_{0}(t)$ is identical across subjects (i.e., has no dependency on $i$). The subject-specific risk of event occurrence is captured through the relative hazards $\\{\\theta(x_{i})\\}_{i = 1, \\dots, N}$.\n",
    "\n",
    "We train a multi-layer perceptron (MLP) to model the subject-specific risk of event occurrence, i.e., the log relative hazards $\\log\\theta(x_{i})$. Patients with lower recurrence time are assumed to have higher risk of event. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46343fe0",
   "metadata": {},
   "source": [
    "### Section 1.1: MLP model for log relative hazards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2bd89a-c90a-4795-aab5-b5c21906a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cox_model = torch.nn.Sequential(\n",
    "    torch.nn.BatchNorm1d(num_features),  # Batch normalization\n",
    "    torch.nn.Linear(num_features, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(),\n",
    "    torch.nn.Linear(32, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(),\n",
    "    torch.nn.Linear(64, 1),  # Estimating log hazards for Cox models\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c90244",
   "metadata": {},
   "source": [
    "### Section 1.2: MLP model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7889dc1-1cfa-424e-a586-481cbc789581",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Init optimizer for Cox\n",
    "optimizer = torch.optim.Adam(cox_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Initiate empty list to store the loss on the train and validation sets\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = torch.tensor(0.0)\n",
    "    for i, batch in enumerate(dataloader_train):\n",
    "        x, (event, time) = batch\n",
    "        optimizer.zero_grad()\n",
    "        log_hz = cox_model(x)  # shape = (16, 1)\n",
    "        loss = neg_partial_log_likelihood(log_hz, event, time, reduction=\"mean\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.detach()\n",
    "\n",
    "    if epoch % (EPOCHS // 10) == 0:\n",
    "        print(f\"Epoch: {epoch:03}, Training loss: {epoch_loss:0.2f}\")\n",
    "\n",
    "    # Reccord loss on train and test sets\n",
    "    epoch_loss /= i + 1\n",
    "    train_losses.append(epoch_loss)\n",
    "    with torch.no_grad():\n",
    "        x, (event, time) = next(iter(dataloader_val))\n",
    "        val_losses.append(\n",
    "            neg_partial_log_likelihood(cox_model(x), event, time, reduction=\"mean\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2bdd8c-f84c-4003-98f4-220ddab518d1",
   "metadata": {},
   "source": [
    "We can visualize the training and validation losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21afc248-303a-4156-8d9c-b97be3e0a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_losses, val_losses, \"Cox\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd881d14-9646-48e0-bcc3-f29be358161f",
   "metadata": {},
   "source": [
    "### Section 1.3: Cox proportional hazards model evaluation\n",
    "\n",
    "We evaluate the predictive performance of the model using \n",
    "\n",
    "* the [concordance index](../_autosummary/torchsurv.metrics.cindex.html) (C-index), which measures the the probability that a model correctly predicts which of two comparable samples will experience an event first based on their estimated risk scores,\n",
    "* the [Area Under the Receiver Operating Characteristic Curve](../_autosummary/torchsurv.metrics.auc.html) (AUC), which measures the probability that a model correctly predicts which of two comparable samples will experience an event by time t based on their estimated risk scores.\n",
    "\n",
    "We cannot use the Brier score because this model is not able to estimate the survival function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2e7996",
   "metadata": {},
   "source": [
    "We start by evaluating the subject-specific relative hazards on the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a997d-a978-4e9b-bb0b-d90e4f03a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "cox_model.eval()\n",
    "with torch.no_grad():\n",
    "    # test event and test time of length n\n",
    "    x, (event, time) = next(iter(dataloader_test))\n",
    "    log_hz = cox_model(x)  # log hazard of length n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bd0fe9",
   "metadata": {},
   "source": [
    "We obtain the concordance index, and its confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9ad489-9e53-40ac-8931-8941597760a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concordance index\n",
    "cox_cindex = ConcordanceIndex()\n",
    "print(\"Cox model performance:\")\n",
    "print(f\"Concordance-index   = {cox_cindex(log_hz, event, time)}\")\n",
    "print(f\"Confidence interval = {cox_cindex.confidence_interval()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507b410a",
   "metadata": {},
   "source": [
    "We can also test whether the observed concordance index is greater than 0.5. The statistical test is specified with H0: c-index = 0.5 and Ha: c-index > 0.5. The p-value of the statistical test is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d34ba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H0: cindex = 0.5, Ha: cindex > 0.5\n",
    "print(\"p-value = {}\".format(cox_cindex.p_value(alternative=\"greater\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60919a9",
   "metadata": {},
   "source": [
    "For time-dependent prediction (e.g., 5-year mortality), the C-index is not a proper measure. Instead, it is recommended to use the AUC. The probability to correctly predicts which of two comparable patients will experience an event by 5-year based on their estimated risk scores is the AUC evaluated at 5-year (1825 days) obtained with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907312f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cox_auc = Auc()\n",
    "\n",
    "new_time = torch.tensor(1825.0)\n",
    "\n",
    "# auc evaluated at new time = 1825, 5 year\n",
    "print(f\"AUC 5-yr             = {cox_auc(log_hz, event, time, new_time=new_time)}\")\n",
    "print(f\"AUC 5-yr (conf int.) = {cox_auc.confidence_interval()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e7e69f",
   "metadata": {},
   "source": [
    "As before, we can test whether the observed Auc at 5-year is greater than 0.5. The statistical test is specified with H0: auc = 0.5 and Ha: auc > 0.5. The p-value of the statistical test is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e5a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"AUC (p_value) = {cox_auc.p_value()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f517e6-b0a4-4fbc-aac5-b500b4aca169",
   "metadata": {},
   "source": [
    "## Section 2: Weibull accelerated failure time (AFT) model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769ddcf5",
   "metadata": {},
   "source": [
    "In this section, we use the [Weibull accelerated failure (AFT) model](../_autosummary/torchsurv.loss.weibull.html). Given covariate $x_{i}$, the hazard of patient $i$ at time $t$ has the form\n",
    "$$\n",
    "\\lambda (t|x_{i}) = \\frac{\\rho(x_{i}) } {\\lambda(x_{i}) } + \\left(\\frac{t}{\\lambda(x_{i})}\\right)^{\\rho(x_{i}) - 1}\n",
    "$$\n",
    "\n",
    "Given the hazard form, it can be shown that the event density follows a Weibull distribution parametrized by scale $\\lambda(x_{i})$ and shape $\\rho(x_{i})$. The subject-specific risk of event occurrence at time $t$ is captured through the hazards $\\{\\lambda (t|x_{i})\\}_{i = 1, \\dots, N}$. We train a multi-layer perceptron (MLP) to model the subject-specific log scale, $\\log \\lambda(x_{i})$, and the log shape, $\\log\\rho(x_{i})$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a580702e",
   "metadata": {},
   "source": [
    "### Section 2.1: MLP model for log scale and log shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b92c10-e5fb-491d-9e27-743bcffdced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same architecture than Cox model, beside outputs dimension\n",
    "weibull_model = torch.nn.Sequential(\n",
    "    torch.nn.BatchNorm1d(num_features),  # Batch normalization\n",
    "    torch.nn.Linear(num_features, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(),\n",
    "    torch.nn.Linear(32, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(),\n",
    "    torch.nn.Linear(64, 2),  # Estimating log parameters for Weibull model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96c6985",
   "metadata": {},
   "source": [
    "### Section 2.2: MLP model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c6f77-6245-42b0-ae48-33b57789b651",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Init optimizer for Weibull\n",
    "optimizer = torch.optim.Adam(weibull_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Initialize empty list to store loss on train and validation sets\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = torch.tensor(0.0)\n",
    "    for i, batch in enumerate(dataloader_train):\n",
    "        x, (event, time) = batch\n",
    "        optimizer.zero_grad()\n",
    "        log_params = weibull_model(x)  # shape = (16, 2)\n",
    "        loss = neg_log_likelihood(log_params, event, time, reduction=\"mean\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.detach()\n",
    "\n",
    "    if epoch % (EPOCHS // 10) == 0:\n",
    "        print(f\"Epoch: {epoch:03}, Training loss: {epoch_loss:0.2f}\")\n",
    "\n",
    "    # Reccord losses for the following figure\n",
    "    train_losses.append(epoch_loss)\n",
    "    with torch.no_grad():\n",
    "        x, (event, time) = next(iter(dataloader_val))\n",
    "        val_losses.append(\n",
    "            neg_log_likelihood(weibull_model(x), event, time, reduction=\"mean\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aba21b6",
   "metadata": {},
   "source": [
    "We can visualize the training and validation losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243a4fa9-f751-46e7-83f3-e623bfd3518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_losses, val_losses, \"Weibull\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86139132-d337-47b7-a8ad-eac1e255f91d",
   "metadata": {},
   "source": [
    "### Section 2.3: Weibull AFT model evaluation\n",
    "\n",
    "We evaluate the predictive performance of the model using \n",
    "\n",
    "* the [C-index](../_autosummary/torchsurv.metrics.cindex.html), which measures the the probability that a model correctly predicts which of two comparable samples will experience an event first based on their estimated risk scores,\n",
    "* the [AUC](../_autosummary/torchsurv.metrics.auc.html), which measures the probability that a model correctly predicts which of two comparable samples will experience an event by time t based on their estimated risk scores, and\n",
    "* the [Brier score](../_autosummary/torchsurv.metrics.brier_score.html), which measures the model's calibration by calculating the mean square error between the estimated survival function and the empirical (i.e., in-sample) event status."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb226f5",
   "metadata": {},
   "source": [
    "We start by obtaining the subject-specific log hazard and survival probability at every time $t$ observed on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11599a1f-597b-4ebf-8a15-d3f9db1ebcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "weibull_model.eval()\n",
    "with torch.no_grad():\n",
    "    # event and time of length n\n",
    "    x, (event, time) = next(iter(dataloader_test))\n",
    "    log_params = weibull_model(x)  # shape = (n,2)\n",
    "\n",
    "# Compute the log hazards from weibull log parameters\n",
    "log_hz = log_hazard(log_params, time)  # shape = (n,n)\n",
    "\n",
    "# Compute the survival probability from weibull log parameters\n",
    "surv = survival_function(log_params, time)  # shape = (n,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e309515",
   "metadata": {},
   "source": [
    "We can evaluate the concordance index, its confidence interval and the p-value of the statistical test testing whether the c-index is greater than 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd7e7a5-c909-41eb-a48f-a9c9832eb33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concordance index\n",
    "weibull_cindex = ConcordanceIndex()\n",
    "print(\"Weibull model performance:\")\n",
    "print(f\"Concordance-index   = {weibull_cindex(log_hz, event, time)}\")\n",
    "print(f\"Confidence interval = {weibull_cindex.confidence_interval()}\")\n",
    "\n",
    "# H0: cindex = 0.5, Ha: cindex >0.5\n",
    "print(f\"p-value             = {weibull_cindex.p_value(alternative = 'greater')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d985e48c",
   "metadata": {},
   "source": [
    "For time-dependent prediction (e.g., 5-year mortality), the C-index is not a proper measure. Instead, it is recommended to use the AUC. The probability to correctly predicts which of two comparable patients will experience an event by 5-year based on their estimated risk scores is the AUC evaluated at 5-year (1825 days) obtained with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_time = torch.tensor(1825.0)\n",
    "\n",
    "# subject-specific log hazard at \\5-yr\n",
    "log_hz_t = log_hazard(log_params, time=new_time)  # shape = (n)\n",
    "weibull_auc = Auc()\n",
    "\n",
    "# auc evaluated at new time = 1825, 5 year\n",
    "print(f\"AUC 5-yr             = {weibull_auc(log_hz_t, event, time, new_time=new_time)}\")\n",
    "print(f\"AUC 5-yr (conf int.) = {weibull_auc.confidence_interval()}\")\n",
    "print(f\"AUC 5-yr (p value)   = {weibull_auc.p_value(alternative='greater')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b00e9f",
   "metadata": {},
   "source": [
    "Lastly, we can evaluate the time-dependent Brier score and the integrated Brier score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d99480-b643-4836-acd3-7614fa903543",
   "metadata": {},
   "outputs": [],
   "source": [
    "brier_score = BrierScore()\n",
    "\n",
    "# brier score at first 5 times\n",
    "print(f\"Brier score             = {brier_score(surv, event, time)[:5]}\")\n",
    "print(f\"Brier score (conf int.) = {brier_score.confidence_interval()[:,:5]}\")\n",
    "\n",
    "# integrated brier score\n",
    "print(f\"Integrated Brier score  = {brier_score.integral()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca1d08c",
   "metadata": {},
   "source": [
    "We can test whether the time-dependent Brier score is smaller than what would be expected if the survival model was not providing accurate predictions beyond random chance. We use a bootstrap permutation test and obtain the p-value with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9754fdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H0: bs = bs0, Ha: bs < bs0; where bs0 is the expected brier score if the survival model was not providing accurate predictions beyond random chance.\n",
    "\n",
    "# p-value for brier score at first 5 times\n",
    "print(f\"Brier score (p-val)        = {brier_score.p_value(alternative = 'less')[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f7e7f6-8f07-4f82-8653-8d0d2d1ed84f",
   "metadata": {},
   "source": [
    "## Section 3: Models comparison\n",
    "\n",
    "We can compare the predictive performance of the Cox proportional hazards model against the Weibull AFT model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed057468-ce75-4d3e-a825-71b55effcec8",
   "metadata": {},
   "source": [
    "### Section 3.1: Concordance index\n",
    "The statistical test is formulated as follows, H0: cindex cox = cindex weibull, Ha: cindex cox > cindex weibull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea66963f-2537-4390-bb65-c773275b292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cox cindex     = {cox_cindex.cindex}\")\n",
    "print(f\"Weibull cindex = {weibull_cindex.cindex}\")\n",
    "print(\"p-value        = {}\".format(cox_cindex.compare(weibull_cindex)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f478e8df",
   "metadata": {},
   "source": [
    "### Section 3.2: AUC at 5-year\n",
    "\n",
    "The statistical test is formulated as follows, H0: 5-yr auc cox = 5-yr auc weibull, Ha: 5-yr auc cox > 5-yr auc weibull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4e1651",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cox 5-yr AUC     = {cox_auc.auc}\")\n",
    "print(f\"Weibull 5-yr AUC = {weibull_auc.auc}\")\n",
    "print(\"p-value          = {}\".format(cox_auc.compare(weibull_auc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a00b69",
   "metadata": {},
   "source": [
    "## Section 4: Kaplan Meier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ec8b7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Kaplan-Meier estimator\n",
    "km = KaplanMeierEstimator()\n",
    "\n",
    "# Use our observed testing dataset \n",
    "event = torch.tensor(df_test['cens'].values).bool()\n",
    "time = torch.tensor(df_test['time'].values)\n",
    "\n",
    "# Compute the estimator\n",
    "km(event, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f57051c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot estimate\n",
    "km.plot_km()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0716ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time\tSurvival\n",
      "----------------\n",
      "67.00\t1.0000\n",
      "113.00\t0.9951\n",
      "114.00\t0.9951\n",
      "171.00\t0.9902\n",
      "173.00\t0.9853\n",
      "181.00\t0.9804\n",
      "191.00\t0.9755\n",
      "213.00\t0.9755\n",
      "223.00\t0.9706\n",
      "233.00\t0.9657\n",
      "238.00\t0.9607\n",
      "241.00\t0.9558\n",
      "242.00\t0.9509\n",
      "251.00\t0.9460\n",
      "272.00\t0.9410\n",
      "275.00\t0.9361\n",
      "281.00\t0.9262\n",
      "288.00\t0.9213\n",
      "296.00\t0.9213\n",
      "308.00\t0.9114\n",
      "310.00\t0.9114\n",
      "344.00\t0.9064\n",
      "350.00\t0.9015\n",
      "357.00\t0.8965\n",
      "370.00\t0.8915\n",
      "371.00\t0.8865\n",
      "372.00\t0.8815\n",
      "392.00\t0.8765\n",
      "420.00\t0.8716\n",
      "426.00\t0.8666\n",
      "432.00\t0.8666\n",
      "436.00\t0.8616\n",
      "446.00\t0.8566\n",
      "448.00\t0.8516\n",
      "476.00\t0.8466\n",
      "481.00\t0.8415\n",
      "486.00\t0.8365\n",
      "488.00\t0.8365\n",
      "491.00\t0.8315\n",
      "495.00\t0.8265\n",
      "498.00\t0.8214\n",
      "500.00\t0.8164\n",
      "504.00\t0.8113\n",
      "518.00\t0.8063\n",
      "535.00\t0.8013\n",
      "548.00\t0.7962\n",
      "552.00\t0.7912\n",
      "564.00\t0.7861\n",
      "575.00\t0.7811\n",
      "577.00\t0.7761\n",
      "586.00\t0.7710\n",
      "594.00\t0.7660\n",
      "595.00\t0.7609\n",
      "612.00\t0.7559\n",
      "622.00\t0.7509\n",
      "623.00\t0.7509\n",
      "628.00\t0.7509\n",
      "637.00\t0.7458\n",
      "646.00\t0.7406\n",
      "648.00\t0.7355\n",
      "650.00\t0.7304\n",
      "712.00\t0.7253\n",
      "717.00\t0.7253\n",
      "729.00\t0.7201\n",
      "737.00\t0.7201\n",
      "742.00\t0.7149\n",
      "753.00\t0.7149\n",
      "761.00\t0.7149\n",
      "768.00\t0.7149\n",
      "776.00\t0.7096\n",
      "795.00\t0.7042\n",
      "798.00\t0.7042\n",
      "799.00\t0.6988\n",
      "825.00\t0.6988\n",
      "827.00\t0.6934\n",
      "828.00\t0.6934\n",
      "854.00\t0.6934\n",
      "855.00\t0.6879\n",
      "857.00\t0.6879\n",
      "859.00\t0.6879\n",
      "866.00\t0.6823\n",
      "870.00\t0.6823\n",
      "888.00\t0.6823\n",
      "890.00\t0.6766\n",
      "956.00\t0.6710\n",
      "960.00\t0.6653\n",
      "964.00\t0.6596\n",
      "969.00\t0.6596\n",
      "970.00\t0.6596\n",
      "982.00\t0.6538\n",
      "983.00\t0.6480\n",
      "1002.00\t0.6422\n",
      "1013.00\t0.6422\n",
      "1036.00\t0.6364\n",
      "1043.00\t0.6306\n",
      "1062.00\t0.6306\n",
      "1080.00\t0.6247\n",
      "1089.00\t0.6247\n",
      "1090.00\t0.6187\n",
      "1093.00\t0.6127\n",
      "1094.00\t0.6067\n",
      "1095.00\t0.6067\n",
      "1105.00\t0.6006\n",
      "1109.00\t0.6006\n",
      "1119.00\t0.6006\n",
      "1140.00\t0.5944\n",
      "1152.00\t0.5944\n",
      "1157.00\t0.5882\n",
      "1171.00\t0.5882\n",
      "1177.00\t0.5882\n",
      "1208.00\t0.5882\n",
      "1212.00\t0.5882\n",
      "1222.00\t0.5882\n",
      "1225.00\t0.5816\n",
      "1231.00\t0.5816\n",
      "1233.00\t0.5816\n",
      "1283.00\t0.5816\n",
      "1306.00\t0.5747\n",
      "1317.00\t0.5747\n",
      "1323.00\t0.5747\n",
      "1329.00\t0.5677\n",
      "1340.00\t0.5677\n",
      "1341.00\t0.5677\n",
      "1343.00\t0.5605\n",
      "1349.00\t0.5605\n",
      "1350.00\t0.5605\n",
      "1356.00\t0.5605\n",
      "1357.00\t0.5605\n",
      "1387.00\t0.5530\n",
      "1401.00\t0.5530\n",
      "1434.00\t0.5530\n",
      "1459.00\t0.5452\n",
      "1463.00\t0.5374\n",
      "1472.00\t0.5374\n",
      "1483.00\t0.5374\n",
      "1486.00\t0.5374\n",
      "1490.00\t0.5374\n",
      "1499.00\t0.5374\n",
      "1502.00\t0.5289\n",
      "1505.00\t0.5289\n",
      "1525.00\t0.5202\n",
      "1527.00\t0.5202\n",
      "1528.00\t0.5114\n",
      "1557.00\t0.5114\n",
      "1560.00\t0.5114\n",
      "1589.00\t0.5022\n",
      "1632.00\t0.5022\n",
      "1645.00\t0.5022\n",
      "1666.00\t0.5022\n",
      "1675.00\t0.4926\n",
      "1701.00\t0.4926\n",
      "1707.00\t0.4926\n",
      "1714.00\t0.4926\n",
      "1720.00\t0.4926\n",
      "1721.00\t0.4926\n",
      "1722.00\t0.4926\n",
      "1730.00\t0.4814\n",
      "1743.00\t0.4814\n",
      "1751.00\t0.4814\n",
      "1756.00\t0.4814\n",
      "1760.00\t0.4814\n",
      "1781.00\t0.4814\n",
      "1786.00\t0.4814\n",
      "1789.00\t0.4814\n",
      "1814.00\t0.4539\n",
      "1821.00\t0.4539\n",
      "1833.00\t0.4539\n",
      "1834.00\t0.4539\n",
      "1840.00\t0.4539\n",
      "1852.00\t0.4539\n",
      "1862.00\t0.4539\n",
      "1878.00\t0.4539\n",
      "1884.00\t0.4539\n",
      "1905.00\t0.4539\n",
      "1975.00\t0.4350\n",
      "1977.00\t0.4161\n",
      "1979.00\t0.4161\n",
      "2009.00\t0.4161\n",
      "2017.00\t0.4161\n",
      "2018.00\t0.3929\n",
      "2024.00\t0.3929\n",
      "2030.00\t0.3684\n",
      "2039.00\t0.3438\n",
      "2056.00\t0.3438\n",
      "2065.00\t0.3438\n",
      "2128.00\t0.3438\n",
      "2161.00\t0.3438\n",
      "2195.00\t0.3438\n",
      "2205.00\t0.3438\n",
      "2217.00\t0.3438\n",
      "2237.00\t0.3438\n",
      "2297.00\t0.3438\n",
      "2372.00\t0.3438\n",
      "2380.00\t0.3438\n",
      "2388.00\t0.3438\n",
      "2456.00\t0.3438\n",
      "2563.00\t0.3438\n",
      "torch.Size([1, 50, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "# Print the survival values at each time step\n",
    "km.print_survival_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7563eec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchsurv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
